# MISpace Hackathon - Data Science Project

A comprehensive Python data science project template with FastAPI backend, interactive dashboard, and machine learning capabilities.

## ğŸš€ Features

- **FastAPI Backend**: RESTful API with automatic documentation
- **Interactive Dashboard**: Real-time data visualization and analytics
- **Data Processing Pipeline**: Robust data cleaning and transformation utilities
- **Machine Learning Models**: Example ML models with training and prediction
- **Jupyter Notebooks**: Interactive data exploration and analysis
- **Docker Support**: Easy deployment with Docker and Docker Compose
- **Testing Suite**: Comprehensive unit tests with pytest
- **Code Quality**: Linting, formatting, and type checking tools

## ğŸ“ Project Structure

```
MISpaceHackathon/
â”œâ”€â”€ config/                 # Configuration management
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py        # Application settings
â”œâ”€â”€ data/                  # Data storage
â”‚   â”œâ”€â”€ raw/              # Raw data files
â”‚   â”œâ”€â”€ processed/        # Processed data files
â”‚   â””â”€â”€ external/         # External data sources
â”œâ”€â”€ frontend/             # Dashboard frontend
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ css/         # Stylesheets
â”‚   â”‚   â””â”€â”€ js/          # JavaScript files
â”‚   â””â”€â”€ templates/       # HTML templates
â”‚       â””â”€â”€ index.html   # Main dashboard
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â”‚   â””â”€â”€ 01_data_exploration.ipynb
â”œâ”€â”€ scripts/              # Utility scripts
â”‚   â””â”€â”€ generate_sample_data.py
â”œâ”€â”€ src/                  # Source code
â”‚   â”œâ”€â”€ api/             # FastAPI application
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py      # API entry point
â”‚   â”‚   â””â”€â”€ routes.py    # API endpoints
â”‚   â”œâ”€â”€ data_processing/ # Data processing utilities
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ processor.py
â”‚   â”œâ”€â”€ models/          # Machine learning models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ example_model.py
â”‚   â””â”€â”€ utils/           # Helper functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ helpers.py
â”œâ”€â”€ tests/               # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_api.py
â”‚   â”œâ”€â”€ test_data_processing.py
â”‚   â””â”€â”€ test_models.py
â”œâ”€â”€ .env.example         # Environment variables template
â”œâ”€â”€ .gitignore          # Git ignore rules
â”œâ”€â”€ docker-compose.yml  # Docker Compose configuration
â”œâ”€â”€ Dockerfile          # Docker image definition
â”œâ”€â”€ Makefile            # Build automation
â”œâ”€â”€ requirements.txt    # Python dependencies
â””â”€â”€ setup.py            # Package setup

```

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- (Optional) Docker and Docker Compose

### Local Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/ElijahLeeMorgan/MISpaceHackathon.git
   cd MISpaceHackathon
   ```

2. **Create a virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   make install
   # Or directly with pip:
   pip install -r requirements.txt
   ```

4. **Set up environment variables**:
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

5. **Generate sample data** (optional):
   ```bash
   python scripts/generate_sample_data.py
   ```

### Docker Installation

1. **Build and start containers**:
   ```bash
   make docker-build
   make docker-up
   ```

2. **Access the services**:
   - API: http://localhost:8000
   - API Docs: http://localhost:8000/docs
   - Jupyter: http://localhost:8888

## ğŸš¦ Quick Start

### Running the API Server

**Using Make**:
```bash
make start
```

**Direct Python**:
```bash
python -m src.api.main
```

**With custom configuration**:
```bash
API_PORT=8080 python -m src.api.main
```

The API will be available at:
- Dashboard: http://localhost:8000
- Interactive API Docs: http://localhost:8000/docs
- Alternative Docs: http://localhost:8000/redoc

### Running Tests

```bash
# Run all tests
make test

# Run tests with coverage
make test-cov

# Run specific test file
pytest tests/test_api.py -v
```

### Code Quality

```bash
# Lint code
make lint

# Format code
make format

# Type checking
make typecheck
```

## ğŸ“Š API Endpoints

### Health & Status

- `GET /health` - Health check
- `GET /api/status` - API status and information

### Data Operations

- `GET /api/data/summary` - Get data summary statistics
- `POST /api/data/process` - Process data with configuration

### Machine Learning

- `POST /api/predict` - Make predictions with the model

### Visualizations

- `GET /api/visualizations/sample` - Get sample visualization data

## ğŸ¯ Usage Examples

### Making Predictions

```python
import requests

url = "http://localhost:8000/api/predict"
data = {
    "features": [0.5, -0.3, 0.8]
}

response = requests.post(url, json=data)
print(response.json())
```

### Getting Data Summary

```python
import requests

url = "http://localhost:8000/api/data/summary"
response = requests.get(url)
summary = response.json()
print(summary)
```

### Using the Data Processor

```python
from src.data_processing.processor import DataProcessor
import pandas as pd

# Initialize processor
processor = DataProcessor()

# Load data
data = processor.load_data("data/raw/sample_data.csv")

# Clean data
cleaned = processor.clean_data()

# Get statistics
stats = processor.get_statistics()
```

### Training a Model

```python
from src.models.example_model import ExampleModel
import numpy as np

# Create sample data
X = np.random.randn(100, 3)
y = np.random.randint(0, 2, 100)

# Initialize and train model
model = ExampleModel()
model.train(X, y)

# Make prediction
prediction = model.predict([0.5, -0.3, 0.8])
print(prediction)
```

## ğŸ““ Jupyter Notebooks

Start Jupyter to explore the notebooks:

```bash
jupyter notebook notebooks/
```

The included notebook demonstrates:
- Data loading and exploration
- Visualization techniques
- Data processing pipelines
- Model training and prediction

## ğŸ³ Docker Commands

```bash
# Build images
make docker-build

# Start services
make docker-up

# Stop services
make docker-down

# View logs
make docker-logs
```

## ğŸ§ª Development

### Project Setup for Development

1. Install development dependencies:
   ```bash
   make install-dev
   ```

2. Run tests before committing:
   ```bash
   make test
   ```

3. Format and lint your code:
   ```bash
   make format
   make lint
   ```

### Adding New Features

1. Create feature branch
2. Add your code in appropriate directories
3. Write tests in `tests/`
4. Update documentation
5. Run tests and linting
6. Submit pull request

## ğŸ“ Configuration

Configuration is managed through environment variables. See `.env.example` for available options:

- `API_HOST`: API server host (default: 0.0.0.0)
- `API_PORT`: API server port (default: 8000)
- `DATABASE_URL`: Database connection string
- `ENVIRONMENT`: Environment (development/production)
- `LOG_LEVEL`: Logging level (INFO/DEBUG/WARNING/ERROR)

## ğŸ”’ Security

- Never commit `.env` file with secrets
- Change `SECRET_KEY` in production
- Use environment-specific configurations
- Keep dependencies updated

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Authors

- MISpace Hackathon Team

## ğŸ™ Acknowledgments

- FastAPI for the amazing web framework
- Scikit-learn for machine learning capabilities
- Plotly and Chart.js for visualizations
- The open-source community

## ğŸ“ Support

For issues and questions:
- Open an issue on GitHub
- Check the API documentation at `/docs`
- Review the example notebooks

---

Built with â¤ï¸ for the MISpace Hackathon